{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in dataset\n",
    "main = pd.read_csv(\"../data/unprocessed/wildfire-dataset_copy.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FOD_ID', 'FPA_ID', 'SOURCE_SYSTEM_TYPE', 'SOURCE_SYSTEM', 'NWCG_REPORTING_AGENCY', 'NWCG_REPORTING_UNIT_ID', 'NWCG_REPORTING_UNIT_NAME', 'SOURCE_REPORTING_UNIT', 'SOURCE_REPORTING_UNIT_NAME', 'LOCAL_FIRE_REPORT_ID', 'LOCAL_INCIDENT_ID', 'FIRE_CODE', 'FIRE_NAME', 'ICS_209_PLUS_INCIDENT_JOIN_ID', 'ICS_209_PLUS_COMPLEX_JOIN_ID', 'MTBS_ID', 'MTBS_FIRE_NAME', 'COMPLEX_NAME', 'FIRE_YEAR', 'DISCOVERY_DATE', 'DISCOVERY_DOY', 'DISCOVERY_TIME', 'NWCG_CAUSE_CLASSIFICATION', 'NWCG_GENERAL_CAUSE', 'NWCG_CAUSE_AGE_CATEGORY', 'CONT_DATE', 'CONT_DOY', 'CONT_TIME', 'FIRE_SIZE', 'FIRE_SIZE_CLASS', 'LATITUDE', 'LONGITUDE', 'OWNER_DESCR', 'STATE', 'COUNTY', 'FIPS_CODE', 'FIPS_NAME']\n"
     ]
    }
   ],
   "source": [
    "# All columns\n",
    "all_columns = list(main.columns)\n",
    "print(all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plan to drop columns\n",
    "dropped_columns = [\n",
    "    \"ICS_209_PLUS_INCIDENT_JOIN_ID\", \n",
    "    \"ICS_209_PLUS_COMPLEX_JOIN_ID\", \n",
    "    \"MTBS_ID\", \n",
    "    \"MTBS_FIRE_NAME\", \n",
    "    \"COMPLEX_NAME\", \n",
    "    \"LOCAL_FIRE_REPORT_ID\",\n",
    "    \"FIRE_CODE\", \n",
    "    \"FIRE_NAME\", \n",
    "    \"LOCAL_INCIDENT_ID\", \n",
    "    \"NWCG_CAUSE_AGE_CATEGORY\", \n",
    "    \"CONT_DATE\", \n",
    "    \"CONT_DOY\", \n",
    "    \"CONT_TIME\", \n",
    "    \"FIPS_CODE\", \n",
    "    \"FIPS_NAME\", \n",
    "    \"SOURCE_SYSTEM_TYPE\", \n",
    "    \"SOURCE_SYSTEM\", \n",
    "    \"NWCG_REPORTING_AGENCY\",\n",
    "    \"NWCG_REPORTING_UNIT_ID\",\n",
    "    \"NWCG_REPORTING_UNIT_NAME\",\n",
    "    \"SOURCE_REPORTING_UNIT\",\n",
    "    \"SOURCE_REPORTING_UNIT_NAME\",\n",
    "    \"OWNER_DESCR\",\n",
    "    \"FPA_ID\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NWCG_CAUSE_CLASSIFICATION', 'DISCOVERY_TIME', 'LATITUDE', 'FIRE_SIZE_CLASS', 'NWCG_GENERAL_CAUSE', 'STATE', 'DISCOVERY_DOY', 'FIRE_YEAR', 'COUNTY', 'DISCOVERY_DATE', 'LONGITUDE', 'FIRE_SIZE', 'FOD_ID']\n"
     ]
    }
   ],
   "source": [
    "# Creating a new list of columns\n",
    "# Columns in all_columns but not in dropped_columns\n",
    "\n",
    "columns = list(set(all_columns) - set(dropped_columns))\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NWCG_CAUSE_CLASSIFICATION</th>\n",
       "      <th>DISCOVERY_TIME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>NWCG_GENERAL_CAUSE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>DISCOVERY_DOY</th>\n",
       "      <th>FIRE_YEAR</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>FOD_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>40.036944</td>\n",
       "      <td>A</td>\n",
       "      <td>Power generation/transmission/distribution</td>\n",
       "      <td>CA</td>\n",
       "      <td>33</td>\n",
       "      <td>2005</td>\n",
       "      <td>63</td>\n",
       "      <td>2/2/2005 0:00</td>\n",
       "      <td>-121.005833</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natural</td>\n",
       "      <td>845.0</td>\n",
       "      <td>38.933056</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>CA</td>\n",
       "      <td>133</td>\n",
       "      <td>2004</td>\n",
       "      <td>61</td>\n",
       "      <td>5/12/2004 0:00</td>\n",
       "      <td>-120.404444</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>38.984167</td>\n",
       "      <td>A</td>\n",
       "      <td>Debris and open burning</td>\n",
       "      <td>CA</td>\n",
       "      <td>152</td>\n",
       "      <td>2004</td>\n",
       "      <td>17</td>\n",
       "      <td>5/31/2004 0:00</td>\n",
       "      <td>-120.735556</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natural</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>38.559167</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>CA</td>\n",
       "      <td>180</td>\n",
       "      <td>2004</td>\n",
       "      <td>3</td>\n",
       "      <td>6/28/2004 0:00</td>\n",
       "      <td>-119.913333</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natural</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>38.559167</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>CA</td>\n",
       "      <td>180</td>\n",
       "      <td>2004</td>\n",
       "      <td>3</td>\n",
       "      <td>6/28/2004 0:00</td>\n",
       "      <td>-119.933056</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NWCG_CAUSE_CLASSIFICATION  DISCOVERY_TIME   LATITUDE FIRE_SIZE_CLASS  \\\n",
       "0                     Human          1300.0  40.036944               A   \n",
       "1                   Natural           845.0  38.933056               A   \n",
       "2                     Human          1921.0  38.984167               A   \n",
       "3                   Natural          1600.0  38.559167               A   \n",
       "4                   Natural          1600.0  38.559167               A   \n",
       "\n",
       "                           NWCG_GENERAL_CAUSE STATE  DISCOVERY_DOY  FIRE_YEAR  \\\n",
       "0  Power generation/transmission/distribution    CA             33       2005   \n",
       "1                                     Natural    CA            133       2004   \n",
       "2                     Debris and open burning    CA            152       2004   \n",
       "3                                     Natural    CA            180       2004   \n",
       "4                                     Natural    CA            180       2004   \n",
       "\n",
       "  COUNTY  DISCOVERY_DATE   LONGITUDE  FIRE_SIZE  FOD_ID  \n",
       "0     63   2/2/2005 0:00 -121.005833       0.10       1  \n",
       "1     61  5/12/2004 0:00 -120.404444       0.25       2  \n",
       "2     17  5/31/2004 0:00 -120.735556       0.10       3  \n",
       "3      3  6/28/2004 0:00 -119.913333       0.10       4  \n",
       "4      3  6/28/2004 0:00 -119.933056       0.10       5  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the subset of columns to make a new dataframe to use\n",
    "main_dataframe = main[columns]\n",
    "main_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NWCG_CAUSE_CLASSIFICATION         1\n",
       "DISCOVERY_TIME               754468\n",
       "LATITUDE                          0\n",
       "FIRE_SIZE_CLASS                   0\n",
       "NWCG_GENERAL_CAUSE                0\n",
       "STATE                             0\n",
       "DISCOVERY_DOY                     0\n",
       "FIRE_YEAR                         0\n",
       "COUNTY                       657235\n",
       "DISCOVERY_DATE                    0\n",
       "LONGITUDE                         0\n",
       "FIRE_SIZE                         0\n",
       "FOD_ID                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "\n",
    "main_dataframe.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "County Name: ['Plumas County', 'El Dorado County', 'Placer County']\n"
     ]
    }
   ],
   "source": [
    "# Using the coordinates to LATITUDE and LONGITUDE to find the county\n",
    "\n",
    "import reverse_geocoder as rg\n",
    "\n",
    "df = main_dataframe.copy()\n",
    "\n",
    "# empty out all data in \"county\" field\n",
    "df[\"COUNTY\"] = None\n",
    "\n",
    "# list all missing counties\n",
    "missing_counties = df[df[\"COUNTY\"].isna()].copy()\n",
    "\n",
    "# get coordinates for all missing counties\n",
    "coordinates = list(zip(missing_counties.LATITUDE, missing_counties.LONGITUDE))\n",
    "\n",
    "# get data for missing counties\n",
    "counties = rg.search(coordinates)\n",
    "\n",
    "# get county names from counties dictionary\n",
    "county_names =  [county[\"admin2\"] for county in counties]\n",
    "\n",
    "# check first 3 missing counties \n",
    "print(f\"County Name: {county_names[:3]}\")\n",
    "\n",
    "# replace all missing counties with their corresponding counties\n",
    "df.loc[df[\"COUNTY\"].isna(), \"COUNTY\"] = county_names\n",
    "\n",
    "# I have decided to make all current county codes into None values then fill them with their respective county names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have decided to scrap this for the time being, will be converting all counties in to their respective name then encoding them.\n",
    "# will convert county name to county code\n",
    "# https://www2.census.gov/geo/docs/reference/codes2020/national_cousub2020.txt\n",
    "\n",
    "# state_data = pd.read_csv(\"../data/unprocessed/national_cousub2020.txt\", delimiter=\"|\", low_memory=False)\n",
    "\n",
    "# # Create a mapping DataFrame\n",
    "# county_code_map = state_data[['COUNTYNAME', 'COUNTYFP']].drop_duplicates()\n",
    "\n",
    "# # Merge main_dataframe with county_code_map\n",
    "# main_dataframe = pd.merge(main_dataframe, county_code_map, left_on='COUNTY', right_on='COUNTYNAME', how='left')\n",
    "\n",
    "# # Rename the column as needed and drop the extra column\n",
    "# main_dataframe.rename(columns={'COUNTYFP': 'COUNTY_CODE'}, inplace=True)\n",
    "# main_dataframe.drop('COUNTYNAME', axis=1, inplace=True)\n",
    "\n",
    "# Now main_dataframe should have a new column 'COUNTY_CODE' with the corresponding county codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NWCG_CAUSE_CLASSIFICATION</th>\n",
       "      <th>DISCOVERY_TIME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>NWCG_GENERAL_CAUSE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>DISCOVERY_DOY</th>\n",
       "      <th>FIRE_YEAR</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>FOD_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>40.036944</td>\n",
       "      <td>A</td>\n",
       "      <td>Power generation/transmission/distribution</td>\n",
       "      <td>CA</td>\n",
       "      <td>33</td>\n",
       "      <td>2005</td>\n",
       "      <td>Plumas County</td>\n",
       "      <td>2/2/2005 0:00</td>\n",
       "      <td>-121.005833</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natural</td>\n",
       "      <td>845.0</td>\n",
       "      <td>38.933056</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>CA</td>\n",
       "      <td>133</td>\n",
       "      <td>2004</td>\n",
       "      <td>El Dorado County</td>\n",
       "      <td>5/12/2004 0:00</td>\n",
       "      <td>-120.404444</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>38.984167</td>\n",
       "      <td>A</td>\n",
       "      <td>Debris and open burning</td>\n",
       "      <td>CA</td>\n",
       "      <td>152</td>\n",
       "      <td>2004</td>\n",
       "      <td>Placer County</td>\n",
       "      <td>5/31/2004 0:00</td>\n",
       "      <td>-120.735556</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natural</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>38.559167</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>CA</td>\n",
       "      <td>180</td>\n",
       "      <td>2004</td>\n",
       "      <td>Douglas County</td>\n",
       "      <td>6/28/2004 0:00</td>\n",
       "      <td>-119.913333</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natural</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>38.559167</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>CA</td>\n",
       "      <td>180</td>\n",
       "      <td>2004</td>\n",
       "      <td>El Dorado County</td>\n",
       "      <td>6/28/2004 0:00</td>\n",
       "      <td>-119.933056</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NWCG_CAUSE_CLASSIFICATION  DISCOVERY_TIME   LATITUDE FIRE_SIZE_CLASS  \\\n",
       "0                     Human          1300.0  40.036944               A   \n",
       "1                   Natural           845.0  38.933056               A   \n",
       "2                     Human          1921.0  38.984167               A   \n",
       "3                   Natural          1600.0  38.559167               A   \n",
       "4                   Natural          1600.0  38.559167               A   \n",
       "\n",
       "                           NWCG_GENERAL_CAUSE STATE  DISCOVERY_DOY  FIRE_YEAR  \\\n",
       "0  Power generation/transmission/distribution    CA             33       2005   \n",
       "1                                     Natural    CA            133       2004   \n",
       "2                     Debris and open burning    CA            152       2004   \n",
       "3                                     Natural    CA            180       2004   \n",
       "4                                     Natural    CA            180       2004   \n",
       "\n",
       "             COUNTY  DISCOVERY_DATE   LONGITUDE  FIRE_SIZE  FOD_ID  \n",
       "0     Plumas County   2/2/2005 0:00 -121.005833       0.10       1  \n",
       "1  El Dorado County  5/12/2004 0:00 -120.404444       0.25       2  \n",
       "2     Placer County  5/31/2004 0:00 -120.735556       0.10       3  \n",
       "3    Douglas County  6/28/2004 0:00 -119.913333       0.10       4  \n",
       "4  El Dorado County  6/28/2004 0:00 -119.933056       0.10       5  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NWCG_CAUSE_CLASSIFICATION</th>\n",
       "      <th>DISCOVERY_TIME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>NWCG_GENERAL_CAUSE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>DISCOVERY_DOY</th>\n",
       "      <th>FIRE_YEAR</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>FOD_ID</th>\n",
       "      <th>FIRE_MONTH</th>\n",
       "      <th>FIRE_DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>40.036944</td>\n",
       "      <td>A</td>\n",
       "      <td>Power generation/transmission/distribution</td>\n",
       "      <td>CA</td>\n",
       "      <td>33</td>\n",
       "      <td>2005</td>\n",
       "      <td>Plumas County</td>\n",
       "      <td>2005-02-02</td>\n",
       "      <td>-121.005833</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natural</td>\n",
       "      <td>845.0</td>\n",
       "      <td>38.933056</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>CA</td>\n",
       "      <td>133</td>\n",
       "      <td>2004</td>\n",
       "      <td>El Dorado County</td>\n",
       "      <td>2004-05-12</td>\n",
       "      <td>-120.404444</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>38.984167</td>\n",
       "      <td>A</td>\n",
       "      <td>Debris and open burning</td>\n",
       "      <td>CA</td>\n",
       "      <td>152</td>\n",
       "      <td>2004</td>\n",
       "      <td>Placer County</td>\n",
       "      <td>2004-05-31</td>\n",
       "      <td>-120.735556</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natural</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>38.559167</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>CA</td>\n",
       "      <td>180</td>\n",
       "      <td>2004</td>\n",
       "      <td>Douglas County</td>\n",
       "      <td>2004-06-28</td>\n",
       "      <td>-119.913333</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natural</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>38.559167</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>CA</td>\n",
       "      <td>180</td>\n",
       "      <td>2004</td>\n",
       "      <td>El Dorado County</td>\n",
       "      <td>2004-06-28</td>\n",
       "      <td>-119.933056</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NWCG_CAUSE_CLASSIFICATION  DISCOVERY_TIME   LATITUDE FIRE_SIZE_CLASS  \\\n",
       "0                     Human          1300.0  40.036944               A   \n",
       "1                   Natural           845.0  38.933056               A   \n",
       "2                     Human          1921.0  38.984167               A   \n",
       "3                   Natural          1600.0  38.559167               A   \n",
       "4                   Natural          1600.0  38.559167               A   \n",
       "\n",
       "                           NWCG_GENERAL_CAUSE STATE  DISCOVERY_DOY  FIRE_YEAR  \\\n",
       "0  Power generation/transmission/distribution    CA             33       2005   \n",
       "1                                     Natural    CA            133       2004   \n",
       "2                     Debris and open burning    CA            152       2004   \n",
       "3                                     Natural    CA            180       2004   \n",
       "4                                     Natural    CA            180       2004   \n",
       "\n",
       "             COUNTY DISCOVERY_DATE   LONGITUDE  FIRE_SIZE  FOD_ID  FIRE_MONTH  \\\n",
       "0     Plumas County     2005-02-02 -121.005833       0.10       1           2   \n",
       "1  El Dorado County     2004-05-12 -120.404444       0.25       2           5   \n",
       "2     Placer County     2004-05-31 -120.735556       0.10       3           5   \n",
       "3    Douglas County     2004-06-28 -119.913333       0.10       4           6   \n",
       "4  El Dorado County     2004-06-28 -119.933056       0.10       5           6   \n",
       "\n",
       "   FIRE_DAY  \n",
       "0         2  \n",
       "1        12  \n",
       "2        31  \n",
       "3        28  \n",
       "4        28  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting up Discovery date\n",
    "# We already have the year, therefore we only need the month and day from this field.\n",
    "\n",
    "# First we convert this column into datetime datatype\n",
    "df[\"DISCOVERY_DATE\"] = pd.to_datetime(df[\"DISCOVERY_DATE\"])\n",
    "\n",
    "# Now we extract the Month and Day\n",
    "df[\"FIRE_MONTH\"] = df[\"DISCOVERY_DATE\"].dt.month\n",
    "df[\"FIRE_DAY\"] = df[\"DISCOVERY_DATE\"].dt.day\n",
    "\n",
    "# Now we verify change\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NWCG_CAUSE_CLASSIFICATION</th>\n",
       "      <th>DISCOVERY_TIME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>NWCG_GENERAL_CAUSE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>DISCOVERY_DOY</th>\n",
       "      <th>FIRE_YEAR</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>FOD_ID</th>\n",
       "      <th>FIRE_MONTH</th>\n",
       "      <th>FIRE_DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>40.036944</td>\n",
       "      <td>A</td>\n",
       "      <td>Power generation/transmission/distribution</td>\n",
       "      <td>CA</td>\n",
       "      <td>33</td>\n",
       "      <td>2005</td>\n",
       "      <td>Plumas County</td>\n",
       "      <td>-121.005833</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natural</td>\n",
       "      <td>845.0</td>\n",
       "      <td>38.933056</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>CA</td>\n",
       "      <td>133</td>\n",
       "      <td>2004</td>\n",
       "      <td>El Dorado County</td>\n",
       "      <td>-120.404444</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>38.984167</td>\n",
       "      <td>A</td>\n",
       "      <td>Debris and open burning</td>\n",
       "      <td>CA</td>\n",
       "      <td>152</td>\n",
       "      <td>2004</td>\n",
       "      <td>Placer County</td>\n",
       "      <td>-120.735556</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natural</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>38.559167</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>CA</td>\n",
       "      <td>180</td>\n",
       "      <td>2004</td>\n",
       "      <td>Douglas County</td>\n",
       "      <td>-119.913333</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natural</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>38.559167</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>CA</td>\n",
       "      <td>180</td>\n",
       "      <td>2004</td>\n",
       "      <td>El Dorado County</td>\n",
       "      <td>-119.933056</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NWCG_CAUSE_CLASSIFICATION  DISCOVERY_TIME   LATITUDE FIRE_SIZE_CLASS  \\\n",
       "0                     Human          1300.0  40.036944               A   \n",
       "1                   Natural           845.0  38.933056               A   \n",
       "2                     Human          1921.0  38.984167               A   \n",
       "3                   Natural          1600.0  38.559167               A   \n",
       "4                   Natural          1600.0  38.559167               A   \n",
       "\n",
       "                           NWCG_GENERAL_CAUSE STATE  DISCOVERY_DOY  FIRE_YEAR  \\\n",
       "0  Power generation/transmission/distribution    CA             33       2005   \n",
       "1                                     Natural    CA            133       2004   \n",
       "2                     Debris and open burning    CA            152       2004   \n",
       "3                                     Natural    CA            180       2004   \n",
       "4                                     Natural    CA            180       2004   \n",
       "\n",
       "             COUNTY   LONGITUDE  FIRE_SIZE  FOD_ID  FIRE_MONTH  FIRE_DAY  \n",
       "0     Plumas County -121.005833       0.10       1           2         2  \n",
       "1  El Dorado County -120.404444       0.25       2           5        12  \n",
       "2     Placer County -120.735556       0.10       3           5        31  \n",
       "3    Douglas County -119.913333       0.10       4           6        28  \n",
       "4  El Dorado County -119.933056       0.10       5           6        28  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since we split up discovery date we no longer need the field, so we drop it.\n",
    "df = df.drop(columns=[\"DISCOVERY_DATE\"], axis=1)\n",
    "\n",
    "# verify change\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2166753 entries, 0 to 2166752\n",
      "Data columns (total 14 columns):\n",
      " #   Column                     Dtype  \n",
      "---  ------                     -----  \n",
      " 0   NWCG_CAUSE_CLASSIFICATION  object \n",
      " 1   DISCOVERY_TIME             float64\n",
      " 2   LATITUDE                   float64\n",
      " 3   FIRE_SIZE_CLASS            object \n",
      " 4   NWCG_GENERAL_CAUSE         object \n",
      " 5   STATE                      object \n",
      " 6   DISCOVERY_DOY              int64  \n",
      " 7   FIRE_YEAR                  int64  \n",
      " 8   COUNTY                     object \n",
      " 9   LONGITUDE                  float64\n",
      " 10  FIRE_SIZE                  float64\n",
      " 11  FOD_ID                     int64  \n",
      " 12  FIRE_MONTH                 int32  \n",
      " 13  FIRE_DAY                   int32  \n",
      "dtypes: float64(4), int32(2), int64(3), object(5)\n",
      "memory usage: 214.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NWCG_CAUSE_CLASSIFICATION         1\n",
       "DISCOVERY_TIME               754468\n",
       "LATITUDE                          0\n",
       "FIRE_SIZE_CLASS                   0\n",
       "NWCG_GENERAL_CAUSE                0\n",
       "STATE                             0\n",
       "DISCOVERY_DOY                     0\n",
       "FIRE_YEAR                         0\n",
       "COUNTY                            0\n",
       "LONGITUDE                         0\n",
       "FIRE_SIZE                         0\n",
       "FOD_ID                            0\n",
       "FIRE_MONTH                        0\n",
       "FIRE_DAY                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will convert discovery time into time as cyclical showing closeness between 23:59 and 0:00\n",
    "# Issue: Deal with NaN floats, aka missing values\n",
    "\n",
    "# get time mean\n",
    "time_mean = df[\"DISCOVERY_TIME\"].mean()\n",
    "\n",
    "# fill in missing values with the mean \n",
    "df.fillna({\"DISCOVERY_TIME\": time_mean}, inplace=True)\n",
    "\n",
    "# A function to extract the hour and minutes from discovery time.\n",
    "def extract_time(time):\n",
    "    hour = int(time // 100)\n",
    "    minute = int(time % 100)\n",
    "    return hour, minute\n",
    "\n",
    "df[\"FIRE_HOUR\"], df[\"FIRE_MINUTE\"] = zip(*df[\"DISCOVERY_TIME\"].apply(extract_time))\n",
    "\n",
    "df[\"FIRE_HOUR_SIN\"] = np.sin(2 * np.pi * df[\"FIRE_HOUR\"]/24)\n",
    "df[\"FIRE_HOUR_COS\"] = np.cos(2 * np.pi * df[\"FIRE_HOUR\"]/24)\n",
    "df[\"FIRE_MINUTE_SIN\"] = np.sin(2 * np.pi * df[\"FIRE_MINUTE\"]/60)\n",
    "df[\"FIRE_MINUTE_COS\"] = np.cos(2 * np.pi * df[\"FIRE_MINUTE\"]/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NWCG_CAUSE_CLASSIFICATION</th>\n",
       "      <th>DISCOVERY_TIME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>NWCG_GENERAL_CAUSE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>DISCOVERY_DOY</th>\n",
       "      <th>FIRE_YEAR</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>FOD_ID</th>\n",
       "      <th>FIRE_MONTH</th>\n",
       "      <th>FIRE_DAY</th>\n",
       "      <th>FIRE_HOUR</th>\n",
       "      <th>FIRE_MINUTE</th>\n",
       "      <th>FIRE_HOUR_SIN</th>\n",
       "      <th>FIRE_HOUR_COS</th>\n",
       "      <th>FIRE_MINUTE_SIN</th>\n",
       "      <th>FIRE_MINUTE_COS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>40.036944</td>\n",
       "      <td>A</td>\n",
       "      <td>Power generation/transmission/distribution</td>\n",
       "      <td>CA</td>\n",
       "      <td>33</td>\n",
       "      <td>2005</td>\n",
       "      <td>Plumas County</td>\n",
       "      <td>-121.005833</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natural</td>\n",
       "      <td>845.0</td>\n",
       "      <td>38.933056</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>CA</td>\n",
       "      <td>133</td>\n",
       "      <td>2004</td>\n",
       "      <td>El Dorado County</td>\n",
       "      <td>-120.404444</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>38.984167</td>\n",
       "      <td>A</td>\n",
       "      <td>Debris and open burning</td>\n",
       "      <td>CA</td>\n",
       "      <td>152</td>\n",
       "      <td>2004</td>\n",
       "      <td>Placer County</td>\n",
       "      <td>-120.735556</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>-5.877853e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natural</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>38.559167</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>CA</td>\n",
       "      <td>180</td>\n",
       "      <td>2004</td>\n",
       "      <td>Douglas County</td>\n",
       "      <td>-119.913333</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natural</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>38.559167</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>CA</td>\n",
       "      <td>180</td>\n",
       "      <td>2004</td>\n",
       "      <td>El Dorado County</td>\n",
       "      <td>-119.933056</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NWCG_CAUSE_CLASSIFICATION  DISCOVERY_TIME   LATITUDE FIRE_SIZE_CLASS  \\\n",
       "0                     Human          1300.0  40.036944               A   \n",
       "1                   Natural           845.0  38.933056               A   \n",
       "2                     Human          1921.0  38.984167               A   \n",
       "3                   Natural          1600.0  38.559167               A   \n",
       "4                   Natural          1600.0  38.559167               A   \n",
       "\n",
       "                           NWCG_GENERAL_CAUSE STATE  DISCOVERY_DOY  FIRE_YEAR  \\\n",
       "0  Power generation/transmission/distribution    CA             33       2005   \n",
       "1                                     Natural    CA            133       2004   \n",
       "2                     Debris and open burning    CA            152       2004   \n",
       "3                                     Natural    CA            180       2004   \n",
       "4                                     Natural    CA            180       2004   \n",
       "\n",
       "             COUNTY   LONGITUDE  FIRE_SIZE  FOD_ID  FIRE_MONTH  FIRE_DAY  \\\n",
       "0     Plumas County -121.005833       0.10       1           2         2   \n",
       "1  El Dorado County -120.404444       0.25       2           5        12   \n",
       "2     Placer County -120.735556       0.10       3           5        31   \n",
       "3    Douglas County -119.913333       0.10       4           6        28   \n",
       "4  El Dorado County -119.933056       0.10       5           6        28   \n",
       "\n",
       "   FIRE_HOUR  FIRE_MINUTE  FIRE_HOUR_SIN  FIRE_HOUR_COS  FIRE_MINUTE_SIN  \\\n",
       "0         13            0      -0.258819      -0.965926         0.000000   \n",
       "1          8           45       0.866025      -0.500000        -1.000000   \n",
       "2         19           21      -0.965926       0.258819         0.809017   \n",
       "3         16            0      -0.866025      -0.500000         0.000000   \n",
       "4         16            0      -0.866025      -0.500000         0.000000   \n",
       "\n",
       "   FIRE_MINUTE_COS  \n",
       "0     1.000000e+00  \n",
       "1    -1.836970e-16  \n",
       "2    -5.877853e-01  \n",
       "3     1.000000e+00  \n",
       "4     1.000000e+00  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify time change\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can drop the field discovery_time\n",
    "\n",
    "df = df.drop(columns=[\"DISCOVERY_TIME\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NWCG_CAUSE_CLASSIFICATION    1\n",
       "LATITUDE                     0\n",
       "FIRE_SIZE_CLASS              0\n",
       "NWCG_GENERAL_CAUSE           0\n",
       "STATE                        0\n",
       "DISCOVERY_DOY                0\n",
       "FIRE_YEAR                    0\n",
       "COUNTY                       0\n",
       "LONGITUDE                    0\n",
       "FIRE_SIZE                    0\n",
       "FOD_ID                       0\n",
       "FIRE_MONTH                   0\n",
       "FIRE_DAY                     0\n",
       "FIRE_HOUR                    0\n",
       "FIRE_MINUTE                  0\n",
       "FIRE_HOUR_SIN                0\n",
       "FIRE_HOUR_COS                0\n",
       "FIRE_MINUTE_SIN              0\n",
       "FIRE_MINUTE_COS              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NWCG_CAUSE_CLASSIFICATION    0\n",
       "LATITUDE                     0\n",
       "FIRE_SIZE_CLASS              0\n",
       "NWCG_GENERAL_CAUSE           0\n",
       "STATE                        0\n",
       "DISCOVERY_DOY                0\n",
       "FIRE_YEAR                    0\n",
       "COUNTY                       0\n",
       "LONGITUDE                    0\n",
       "FIRE_SIZE                    0\n",
       "FOD_ID                       0\n",
       "FIRE_MONTH                   0\n",
       "FIRE_DAY                     0\n",
       "FIRE_HOUR                    0\n",
       "FIRE_MINUTE                  0\n",
       "FIRE_HOUR_SIN                0\n",
       "FIRE_HOUR_COS                0\n",
       "FIRE_MINUTE_SIN              0\n",
       "FIRE_MINUTE_COS              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will drop the record where their is a missing value in the following field, then check for any more missing values.\n",
    "df = df.dropna(subset=[\"NWCG_CAUSE_CLASSIFICATION\"])\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2166752 entries, 0 to 2166752\n",
      "Data columns (total 19 columns):\n",
      " #   Column                     Dtype  \n",
      "---  ------                     -----  \n",
      " 0   NWCG_CAUSE_CLASSIFICATION  object \n",
      " 1   LATITUDE                   float64\n",
      " 2   FIRE_SIZE_CLASS            object \n",
      " 3   NWCG_GENERAL_CAUSE         object \n",
      " 4   STATE                      object \n",
      " 5   DISCOVERY_DOY              int64  \n",
      " 6   FIRE_YEAR                  int64  \n",
      " 7   COUNTY                     object \n",
      " 8   LONGITUDE                  float64\n",
      " 9   FIRE_SIZE                  float64\n",
      " 10  FOD_ID                     int64  \n",
      " 11  FIRE_MONTH                 int32  \n",
      " 12  FIRE_DAY                   int32  \n",
      " 13  FIRE_HOUR                  int64  \n",
      " 14  FIRE_MINUTE                int64  \n",
      " 15  FIRE_HOUR_SIN              float64\n",
      " 16  FIRE_HOUR_COS              float64\n",
      " 17  FIRE_MINUTE_SIN            float64\n",
      " 18  FIRE_MINUTE_COS            float64\n",
      "dtypes: float64(7), int32(2), int64(5), object(5)\n",
      "memory usage: 314.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert all objects into numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will begin by looking at how the data looks like for each column that has object data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Human', 'Natural', 'Missing data/not specified/undetermined'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"NWCG_CAUSE_CLASSIFICATION\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'G', 'C', 'D', 'F', 'E'], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"FIRE_SIZE_CLASS\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA', 'NM', 'OR', 'NC', 'WY', 'CO', 'WA', 'MT', 'UT', 'AZ', 'SD',\n",
       "       'AR', 'NV', 'ID', 'MN', 'TX', 'FL', 'SC', 'LA', 'OK', 'KS', 'MO',\n",
       "       'NE', 'MI', 'KY', 'OH', 'IN', 'VA', 'IL', 'TN', 'GA', 'AK', 'ND',\n",
       "       'WV', 'WI', 'AL', 'NH', 'PA', 'MS', 'ME', 'VT', 'NY', 'IA', 'DC',\n",
       "       'MD', 'CT', 'MA', 'NJ', 'HI', 'DE', 'PR', 'RI'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"STATE\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Power generation/transmission/distribution', 'Natural',\n",
       "       'Debris and open burning',\n",
       "       'Missing data/not specified/undetermined',\n",
       "       'Recreation and ceremony', 'Equipment and vehicle use',\n",
       "       'Arson/incendiarism', 'Fireworks', 'Other causes',\n",
       "       'Railroad operations and maintenance', 'Smoking',\n",
       "       'Misuse of fire by a minor', 'Firearms and explosives use'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"NWCG_GENERAL_CAUSE\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Plumas County', 'El Dorado County', 'Placer County', ...,\n",
       "       'Kenosha County', 'Pepin County', 'Moultrie County'], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"COUNTY\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the encoding begin, I will be merging the column \"STATE\" and \"COUNTY\" because their may be some counties that have the same name across different states. \n",
    "\n",
    "After that I will use One hot encoder on the following columns, \"NWCG_CAUSE_CLASSIFICATION\", \"NWCG_GENERAL_CAUSE\", and \"STATE_COUNTY\".\n",
    "\n",
    "Since their is no hierarchy in these three columns one hot encoding will be a good choice. \n",
    "\n",
    "Then I will apply ordinal encoding to the column \"FIRE_SIZE_CLASS\" because I would like to show an order between A - G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2166752 entries, 0 to 2166752\n",
      "Data columns (total 19 columns):\n",
      " #   Column                     Dtype  \n",
      "---  ------                     -----  \n",
      " 0   NWCG_CAUSE_CLASSIFICATION  object \n",
      " 1   LATITUDE                   float64\n",
      " 2   FIRE_SIZE_CLASS            object \n",
      " 3   NWCG_GENERAL_CAUSE         object \n",
      " 4   STATE                      object \n",
      " 5   DISCOVERY_DOY              int64  \n",
      " 6   FIRE_YEAR                  int64  \n",
      " 7   COUNTY                     object \n",
      " 8   LONGITUDE                  float64\n",
      " 9   FIRE_SIZE                  float64\n",
      " 10  FOD_ID                     int64  \n",
      " 11  FIRE_MONTH                 int32  \n",
      " 12  FIRE_DAY                   int32  \n",
      " 13  FIRE_HOUR                  int64  \n",
      " 14  FIRE_MINUTE                int64  \n",
      " 15  FIRE_HOUR_SIN              float64\n",
      " 16  FIRE_HOUR_COS              float64\n",
      " 17  FIRE_MINUTE_SIN            float64\n",
      " 18  FIRE_MINUTE_COS            float64\n",
      "dtypes: float64(7), int32(2), int64(5), object(5)\n",
      "memory usage: 314.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# concatenate state and county\n",
    "df[\"STATE_COUNTY\"] = df[\"STATE\"] + \"-\" + df[\"COUNTY\"]\n",
    "\n",
    "# selecting columns that we will encode for onehotencoding\n",
    "columns_to_encode_oh = [\"NWCG_CAUSE_CLASSIFICATION\", \"NWCG_GENERAL_CAUSE\", \"STATE_COUNTY\"]\n",
    "\n",
    "# Instatiate OneHotEncoder \n",
    "oh_encoder = OneHotEncoder()\n",
    "\n",
    "# Fit and transform \n",
    "oh_encoded = oh_encoder.fit_transform(df[columns_to_encode_oh])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now encoding fire_size_class with ordinal\n",
    "ordinal_encoder = OrdinalEncoder(categories=[[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"FIRE_SIZE_CLASS_ENCODED\"] = ordinal_encoder.fit_transform(df[[\"FIRE_SIZE_CLASS\"]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a df with the encoded data \n",
    "oh_encoded_df = pd.DataFrame.sparse.from_spmatrix(oh_encoded, columns=oh_encoder.get_feature_names_out(columns_to_encode_oh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one hot encoding duplicate columns: Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# verifying that the columns after the one hot encoding are or are not being duplicated\n",
    "\n",
    "duplicates_oh_df = oh_encoded_df.columns[oh_encoded_df.columns.duplicated()]\n",
    "print(f\"one hot encoding duplicate columns: {duplicates_oh_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later on we can revert the dataset into a dense format for further data analysis here is the code:\n",
    "# df_dense = df_encoded.sparse.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=columns_to_encode_oh + [\"FIRE_SIZE_CLASS\"])\n",
    "\n",
    "final_df = pd.concat([df, oh_encoded_df, df[[\"FIRE_SIZE_CLASS_ENCODED\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop(columns=[\"STATE\", \"COUNTY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will save file as a parquet, make sure to have pyarrow and fastparquet as your dependencies already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: save as csv's "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "troubleshooting duplicates when attempting to save dataframe as csv/parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final dataframe duplicate columns: Index(['FIRE_SIZE_CLASS_ENCODED'], dtype='object')\n",
      "final dataframe duplicate columns after renaming: Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates in the final dataframe\n",
    "duplicates_final = final_df.columns[final_df.columns.duplicated()]\n",
    "print(f\"final dataframe duplicate columns: {duplicates_final}\")\n",
    "\n",
    "# ensure unique column names by renaming duplicates\n",
    "if len(duplicates_final) > 0:\n",
    "    for col in duplicates_final.unique():\n",
    "        col_indices = [i for i, x in enumerate(final_df.columns) if x == col]\n",
    "        for j, idx in enumerate(col_indices):\n",
    "            if j > 0: # skip the first occurrence \n",
    "                final_df.columns.values[idx] = f\"{col}_{j+1}\"\n",
    "\n",
    "\n",
    "# verify that there are no more duplicates after renaming\n",
    "duplicates_final_after = final_df.columns[final_df.columns.duplicated()]\n",
    "print(f\"final dataframe duplicate columns after renaming: {duplicates_final_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Renaming or dropping duplicate columns\n",
    "# for col, count in duplicates.items():\n",
    "#     if count > 1:\n",
    "#         for i in range(count):\n",
    "#             duplicate_col_name = f\"{col}_{i+1}\"\n",
    "#             final_df.columns = [duplicate_col_name if col == name else name for name in final_df.columns]\n",
    "\n",
    "# # Verify that there are no duplicates\n",
    "# column_counts = Counter(final_df.columns)\n",
    "# duplicates = {col: count for col, count in column_counts.items() if count > 1}\n",
    "# print(f\"Duplicate column names and counts after renaming: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # verifying that the initial dataframe does not have any duplicate column names\n",
    "# initial_columns = main_dataframe.columns\n",
    "# duplicates_initial = initial_columns[initial_columns.duplicated()]\n",
    "# print(f\"Initial duplicate columns: {duplicates_initial}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ensure that the encoded columns are unique before merging \n",
    "\n",
    "# oh_encoded_df = pd.DataFrame.sparse.from_spmatrix(oh_encoded, oh_encoded_columns) \n",
    "\n",
    "# duplicates_oh_df = oh_encoded_df.columns[oh_encoded_df.columns.duplicated()]\n",
    "# print(f\"one hot encoding dataframe duplicate columns: {duplicates_oh_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop original columns that were encoded\n",
    "# df = df.drop(columns=columns_to_encode_oh + [\"FIRE_SIZE_CLASS\"])\n",
    "\n",
    "# # Combine DataFrames\n",
    "# final_df = pd.concat([df, oh_encoded_df, df[[\"FIRE_SIZE_CLASS_ENCODED\"]]], axis=1)\n",
    "\n",
    "# # Check for duplicates in the final DataFrame\n",
    "# duplicates_final = final_df.columns[final_df.columns.duplicated()]\n",
    "# print(f\"Final DataFrame duplicate columns: {duplicates_final}\")\n",
    "\n",
    "# # Ensure unique column names by renaming duplicates\n",
    "# if len(duplicates_final) > 0:\n",
    "#     for col in duplicates_final.unique():\n",
    "#         col_indices = [i for i, x in enumerate(final_df.columns) if x == col]\n",
    "#         for j, idx in enumerate(col_indices):\n",
    "#             if j > 0:  # Skip the first occurrence\n",
    "#                 final_df.columns.values[idx] = f\"{col}_{j+1}\"\n",
    "\n",
    "# # Verify that there are no duplicates after renaming\n",
    "# duplicates_final_after = final_df.columns[final_df.columns.duplicated()]\n",
    "# print(f\"Final DataFrame duplicate columns after renaming: {duplicates_final_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final DataFrame to a CSV file\n",
    "final_df.to_parquet('../data/processed/processed_wildfire_data.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfinal_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/processed/processed_wildfire_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\core\\generic.py:3961\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3950\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3952\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3953\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3954\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3958\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3959\u001b[0m )\n\u001b[1;32m-> 3961\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3964\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3966\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:270\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:275\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:320\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    317\u001b[0m slicer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(start_i, end_i)\n\u001b[0;32m    318\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc[slicer]\n\u001b[1;32m--> 320\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_number_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(res\u001b[38;5;241m.\u001b[39m_iter_column_arrays())\n\u001b[0;32m    323\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\core\\frame.py:1399\u001b[0m, in \u001b[0;36mDataFrame._get_values_for_csv\u001b[1;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_values_for_csv\u001b[39m(\n\u001b[0;32m   1390\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   1398\u001b[0m     \u001b[38;5;66;03m# helper used by to_csv\u001b[39;00m\n\u001b[1;32m-> 1399\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(mgr, axes\u001b[38;5;241m=\u001b[39mmgr\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:467\u001b[0m, in \u001b[0;36mBaseBlockManager.get_values_for_csv\u001b[1;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values_for_csv\u001b[39m(\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    462\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    Convert values to native types (strings / python objects) that are used\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    in formatting (repr / csv).\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget_values_for_csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:364\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 364\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    367\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:780\u001b[0m, in \u001b[0;36mBlock.get_values_for_csv\u001b[1;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values_for_csv\u001b[39m(\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    778\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Block:\n\u001b[0;32m    779\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"convert to our native types format\"\"\"\u001b[39;00m\n\u001b[1;32m--> 780\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mget_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(result)\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7856\u001b[0m, in \u001b[0;36mget_values_for_csv\u001b[1;34m(values, date_format, na_rep, quoting, float_format, decimal)\u001b[0m\n\u001b[0;32m   7853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m   7855\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, ExtensionArray):\n\u001b[1;32m-> 7856\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7858\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m))\n\u001b[0;32m   7859\u001b[0m     new_values[mask] \u001b[38;5;241m=\u001b[39m na_rep\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:178\u001b[0m, in \u001b[0;36misna\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_] \u001b[38;5;241m|\u001b[39m NDFrame:\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:207\u001b[0m, in \u001b[0;36m_isna\u001b[1;34m(obj, inf_as_na)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (np\u001b[38;5;241m.\u001b[39mndarray, ABCExtensionArray)):\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minf_as_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, ABCIndex):\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m# Try to use cached isna, which also short-circuits for integer dtypes\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m#  and avoids materializing RangeIndex._values\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_can_hold_na:\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:287\u001b[0m, in \u001b[0;36m_isna_array\u001b[1;34m(values, inf_as_na)\u001b[0m\n\u001b[0;32m    282\u001b[0m         result \u001b[38;5;241m=\u001b[39m libmissing\u001b[38;5;241m.\u001b[39misnaobj(values\u001b[38;5;241m.\u001b[39mto_numpy(), inf_as_na\u001b[38;5;241m=\u001b[39minf_as_na)\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;66;03m# \"Union[ndarray[Any, Any], ExtensionArraySupportsAnyAll]\", variable has\u001b[39;00m\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;66;03m# type \"ndarray[Any, dtype[bool_]]\")\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mrec\u001b[38;5;241m.\u001b[39mrecarray):\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;66;03m# GH 48526\u001b[39;00m\n\u001b[0;32m    290\u001b[0m     result \u001b[38;5;241m=\u001b[39m _isna_recarray_dtype(values, inf_as_na\u001b[38;5;241m=\u001b[39minf_as_na)\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\core\\arrays\\sparse\\array.py:716\u001b[0m, in \u001b[0;36mSparseArray.isna\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    714\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m), \u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n\u001b[0;32m    715\u001b[0m mask[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msp_index\u001b[38;5;241m.\u001b[39mindices] \u001b[38;5;241m=\u001b[39m isna(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msp_values)\n\u001b[1;32m--> 716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\core\\arrays\\sparse\\array.py:475\u001b[0m, in \u001b[0;36mSparseArray.__init__\u001b[1;34m(self, data, sparse_index, fill_value, kind, dtype, copy)\u001b[0m\n\u001b[0;32m    473\u001b[0m                 fill_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime64(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    474\u001b[0m         data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data)\n\u001b[1;32m--> 475\u001b[0m     sparse_values, sparse_index, fill_value \u001b[38;5;241m=\u001b[39m \u001b[43m_make_sparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument \"dtype\" to \"_make_sparse\" has incompatible type\u001b[39;49;00m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \"Union[ExtensionDtype, dtype[Any], None]\"; expected\u001b[39;49;00m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \"Optional[dtype[Any]]\"\u001b[39;49;00m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;66;03m# error: Argument \"dtype\" to \"asarray\" has incompatible type\u001b[39;00m\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionDtype, dtype[Any], None]\"; expected \"None\"\u001b[39;00m\n\u001b[0;32m    487\u001b[0m     sparse_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data, dtype\u001b[38;5;241m=\u001b[39mdtype)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-5hDgaI5H-py3.12\\Lib\\site-packages\\pandas\\core\\arrays\\sparse\\array.py:1895\u001b[0m, in \u001b[0;36m_make_sparse\u001b[1;34m(arr, kind, fill_value, dtype)\u001b[0m\n\u001b[0;32m   1893\u001b[0m     indices \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39msp_index\u001b[38;5;241m.\u001b[39mindices\n\u001b[0;32m   1894\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1895\u001b[0m     indices \u001b[38;5;241m=\u001b[39m \u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1897\u001b[0m index \u001b[38;5;241m=\u001b[39m make_sparse_index(length, indices, kind)\n\u001b[0;32m   1898\u001b[0m sparsified_values \u001b[38;5;241m=\u001b[39m arr[mask]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_df.to_csv(\"../data/processed/processed_wildfire_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save Encoders\n",
    "\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "# Save the onehotencoder\n",
    "dump(oh_encoder, 'onehotencoder.joblib')\n",
    "\n",
    "# save the ordinalencoder \n",
    "dump(ordinal_encoder, 'ordinalencoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cis182-cw-GLlwkkPC-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
