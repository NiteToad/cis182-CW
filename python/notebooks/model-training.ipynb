{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_pickle(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "encoders = {\n",
    "    'one_hot_encoder': load_pickle('../models/one_hot_encoder.pkl'),\n",
    "    'target_encoder_location': load_pickle('../models/target_encoder_location.pkl'),\n",
    "    'target_encoder_size': load_pickle('../models/target_encoder_size.pkl'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_features = pd.read_csv('../data/processed/location_features.csv')\n",
    "location_target = pd.read_csv('../data/processed/location_target.csv')\n",
    "size_features = pd.read_csv('../data/processed/size_features.csv')\n",
    "size_target = pd.read_csv('../data/processed/size_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation sets for the location model\n",
    "X_train_loc, X_val_loc, y_train_loc, y_val_loc = train_test_split(\n",
    "    location_features, location_target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and validation sets for the size Model\n",
    "X_train_size, X_val_size, y_train_size, y_val_size = train_test_split(\n",
    "    size_features, size_target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location Model:\n",
      "Training set size: (1733402, 30) (1733402, 2)\n",
      "Validation set size: (433351, 30) (433351, 2)\n",
      "\n",
      "Size Model:\n",
      "Training set size: (1733402, 32) (1733402, 1)\n",
      "Validation set size: (433351, 32) (433351, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Location Model:\")\n",
    "print(\"Training set size:\", X_train_loc.shape, y_train_loc.shape)\n",
    "print(\"Validation set size:\", X_val_loc.shape, y_val_loc.shape)\n",
    "\n",
    "print(\"\\nSize Model:\")\n",
    "print(\"Training set size:\", X_train_size.shape, y_train_size.shape)\n",
    "print(\"Validation set size:\", X_val_size.shape, y_val_size.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location Model score: 0.8995167937573694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dtorr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cis182-cw-GLlwkkPC-py3.12\\Lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size Model score: 0.22069511448443702\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a Random Forest model for the Location Model\n",
    "rf_loc = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_loc.fit(X_train_loc, y_train_loc)\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "score_loc = rf_loc.score(X_val_loc, y_val_loc)\n",
    "print(\"Location Model score:\", score_loc)\n",
    "\n",
    "# Repeat the process for the Size Model\n",
    "rf_size = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_size.fit(X_train_size, y_train_size)\n",
    "score_size = rf_size.score(X_val_size, y_val_size)\n",
    "print(\"Size Model score:\", score_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/random-forest-location-model.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Assuming your model is stored in the variable `rf_loc`\n",
    "dump(rf_loc, '../models/random-forest-location-model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h5/8xl_2vmd1sn6n8ctlfcf3zy40000gn/T/ipykernel_11251/3064003010.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_size_tuned.fit(X_train_size, y_train_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Size Model score: 0.26100665667813383\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest model with different parameters\n",
    "rf_size_tuned = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_size_tuned.fit(X_train_size, y_train_size)\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "score_size_tuned = rf_size_tuned.score(X_val_size, y_val_size)\n",
    "print(\"Tuned Size Model score:\", score_size_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.1-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from xgboost) (1.9.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size Model score (XGBoost): 0.1794338184592057\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Create an XGBoost model for the Size Model\n",
    "xgb_size = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "xgb_size.fit(X_train_size, np.ravel(y_train_size))\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "score_size_xgb = xgb_size.score(X_val_size, np.ravel(y_val_size))\n",
    "print(\"Size Model score (XGBoost):\", score_size_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Size Model score: 0.24288895017764556\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest model with different parameters\n",
    "rf_size_tuned = RandomForestRegressor(n_estimators=300, max_depth=15, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_size_tuned.fit(X_train_size, np.ravel(y_train_size))\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "score_size_tuned = rf_size_tuned.score(X_val_size, np.ravel(y_val_size))\n",
    "print(\"Tuned Size Model score:\", score_size_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size Model score (Decision Tree): -0.463582962031577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Create a Decision Tree model for the Size Model\n",
    "dt_size = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "dt_size.fit(X_train_size, np.ravel(y_train_size))\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "score_size_dt = dt_size.score(X_val_size, np.ravel(y_val_size))\n",
    "print(\"Size Model score (Decision Tree):\", score_size_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size Model score (Linear Regression): 0.2677419167028622\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a Linear Regression model for the Size Model\n",
    "lr_size = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "lr_size.fit(X_train_size, np.ravel(y_train_size))\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "score_size_lr = lr_size.score(X_val_size, np.ravel(y_val_size))\n",
    "print(\"Size Model score (Linear Regression):\", score_size_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size Model score (Gradient Boosting): 0.29655010860298237\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Create a Gradient Boosting model for the Size Model\n",
    "gb_size = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "gb_size.fit(X_train_size, np.ravel(y_train_size))\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "score_size_gb = gb_size.score(X_val_size, np.ravel(y_val_size))\n",
    "print(\"Size Model score (Gradient Boosting):\", score_size_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_loc = y_train_loc.iloc[:, 0]\n",
    "y_val_loc = y_val_loc.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 7.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 7.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 7.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 7.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 7.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 7.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=15.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=15.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=15.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=23.1min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=15.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=15.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time= 7.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=23.1min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=23.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=15.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time= 7.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time= 7.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=22.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=22.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 7.0min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=14.8min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=22.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=14.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=14.8min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 6.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 6.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=21.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=20.1min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=20.1min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 6.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=13.1min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=13.1min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=13.1min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 6.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 6.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=19.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=19.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time= 6.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=13.0min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=19.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=13.1min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=13.1min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time= 6.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time= 6.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=19.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=19.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time= 6.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=19.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=13.1min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=13.0min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=13.1min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time= 6.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time= 6.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=19.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=19.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=19.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=13.1min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time= 6.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=13.0min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=13.0min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time= 6.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time= 6.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=19.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=19.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=19.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=13.0min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time= 6.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=13.0min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=13.0min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time= 6.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time= 6.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=19.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=19.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=19.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=12.9min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=12.9min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=12.9min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 8.9min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 8.9min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=19.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=19.3min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 8.9min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=19.2min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 8.9min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 8.9min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 8.8min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=17.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=17.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=17.8min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time= 8.8min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=26.6min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=26.6min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=26.6min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=17.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=17.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=17.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time= 8.9min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time= 8.9min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=27.6min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=27.6min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=27.6min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 9.9min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=18.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=18.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=18.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 9.2min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 9.2min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=28.4min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=28.5min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=18.6min\n",
      "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=28.5min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 9.5min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=18.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=18.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 9.0min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 9.0min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=27.5min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=27.5min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time= 8.8min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=27.2min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=17.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=17.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=17.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time= 8.8min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time= 8.8min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=26.6min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=26.5min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time= 8.8min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=26.5min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=17.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=17.6min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=17.6min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time= 8.8min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time= 8.8min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=26.4min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=26.4min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time= 8.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=26.4min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=17.5min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=17.6min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=17.6min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time= 8.8min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time= 8.8min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=26.3min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=26.3min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time= 8.8min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=26.3min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=17.6min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=17.6min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=17.5min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time= 8.8min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time= 8.8min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=26.3min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=26.3min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=26.3min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=17.5min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=17.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=10.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=17.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=10.7min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=10.7min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=26.2min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=26.2min\n",
      "[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=26.1min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=10.6min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=21.2min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=21.3min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=21.2min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=10.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=10.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=10.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=31.8min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=31.8min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=21.0min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=20.9min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=31.8min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=21.0min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=10.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=10.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=31.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=31.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=31.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=10.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=20.8min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=20.8min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=20.8min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=10.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=10.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=31.2min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=31.2min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=10.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=21.0min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=31.2min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=21.0min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=21.0min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=10.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=10.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=31.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=31.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=10.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=20.9min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=31.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=21.0min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=21.0min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=10.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=10.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=31.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=31.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=10.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=31.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=20.8min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=20.8min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=20.9min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=10.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=10.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=31.3min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=31.2min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=10.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=31.3min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=20.9min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=20.8min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=20.8min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=10.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=10.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=31.3min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=31.3min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=10.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=31.3min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=20.8min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=20.9min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=20.9min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=10.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=10.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=30.9min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=30.6min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=30.6min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=19.9min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=19.7min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=19.6min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=25.8min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=25.1min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=24.5min\n",
      "Best parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Location Model score (tuned Random Forest): 0.8129025162988683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_loc, np.ravel(y_train_loc))\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Evaluate the model with the best parameters on the validation data\n",
    "score_location_rf_tuned = grid_search.score(X_val_loc, np.ravel(y_val_loc))\n",
    "print(\"Location Model score (tuned Random Forest):\", score_location_rf_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
